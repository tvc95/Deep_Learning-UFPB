{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 3\n",
    "\n",
    "Usando algoritmos implementados na questão 2, aproxime as funções abaixo. Compare os\n",
    "resultados com as curvas exatas, para o caso dos itens b e c e apresente para cada caso a\n",
    "curva do erro médio de treinamento com relação ao número de épocas e a curva do erro médio com o conjunto de validação. Faça uma análise comparativa sobre a convergência de cada um dos algoritmos.\n",
    "\n",
    "    a) a função lógica XOR;\n",
    "    b) f(x)= sin(pi*x)/(pi*x), 0 <= x <= 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conteúdo da questão anterior\n",
    "\n",
    "## Importações utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import exp, array, random, dot, shape, zeros, transpose, matrix, asscalar\n",
    "from math import ceil, sinh, cosh, floor\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.metrics import classification_report\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes desenvolvidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuronLayer():\n",
    "    \"\"\"\n",
    "    Classe representando a camada de neurônios da rede\n",
    "    Parâmetros:\n",
    "        - num_neurons: o número de neurônios na camada\n",
    "        - num_inputs: o número de entradas que cada neurônio da camada terá\n",
    "    \"\"\"\n",
    "    def __init__(self, num_neurons, num_inputs):\n",
    "        self.weights = 2 * random.random((num_inputs, num_neurons)) - 1\n",
    "        \n",
    "class NeuralNetwork():\n",
    "    def __init__(self, layer1, layer2):\n",
    "        self.layer1 = layer1\n",
    "        self.layer2 = layer2\n",
    "\n",
    "    def activation_func(self, func_name, z):\n",
    "        \"\"\"\n",
    "        Executa uma das funções de ativação da rede\n",
    "        Parâmetros:\n",
    "            - func_name: nome da função de ativação\n",
    "            - z: valor a ser aplicado na função de ativação\n",
    "        \"\"\"\n",
    "        if(func_name == 'sigmoid'):\n",
    "            return 1 / (1 + exp(-z))\n",
    "        elif(func_name == 'tanh'):\n",
    "            return sinh(z) / cosh(z)\n",
    "        elif(func_name == 'relu'):\n",
    "            if(z <= 0):\n",
    "                return 0\n",
    "            else:\n",
    "                return z\n",
    "        elif(func_name == 'sigmoid_deriv'):\n",
    "            return z * (1-z)\n",
    "        elif(func_name == 'relu_deriv'):\n",
    "            if(z<=0):\n",
    "                return 0\n",
    "            else:\n",
    "                return 1\n",
    "\n",
    "    def train_network(self, inputs, expected_outs, num_iterations, learning_rate, backprop_type):\n",
    "        \"\"\"\n",
    "        Método para treinamento da rede neural e ajuste dos pesos sinápticos\n",
    "        Parâmetros:\n",
    "            - inputs: o conjunto de treinamento\n",
    "            - expected_outs: saídas desejadas do conjunto de treinamento\n",
    "            - num_iterations: épocas (duração do treinamento)\n",
    "            - learning_rate: taxa de aprendizado\n",
    "            - backprop_type: o tipo de retropropagação a ser usado no treinamento (\"momentum\", \"batch\", \"stochastic)\n",
    "            \n",
    "        \"\"\"\n",
    "        alpha = 0.1                                     #constante do momento (0 <= alpha < 1)\n",
    "        samples, features = shape(inputs)\n",
    "        layer1_adjustment = 0\n",
    "        layer2_adjustment = 0\n",
    "        \n",
    "        for count in range(num_iterations):\n",
    "            #print(\"época \" + str(count + 1) + \":\")\n",
    "\n",
    "            if((backprop_type == \"batch\") or (backprop_type == \"momentum\")):\n",
    "                out_l1, out_l2 = self.classify(inputs)\n",
    "                \n",
    "                ### Cálculo dos erros na camada 2\n",
    "                layer2_error = expected_outs - out_l2\n",
    "                layer2_grad = layer2_error * self.activation_func(\"sigmoid_deriv\",out_l2)      # gradiente local do neurônio da camada de saída\n",
    "                #print(\"erro camada 2: \\n\" + str(layer2_error))\n",
    "\n",
    "                ## Com base no resultado da camada 2, calcular o erro na camada 1\n",
    "                layer1_error = layer2_grad.dot(self.layer2.weights.T)\n",
    "                layer1_grad = layer1_error * self.activation_func(\"sigmoid_deriv\",out_l1)                 # gradiente da camada 1\n",
    "                #print(\"erro camada 1: \\n\" + str(layer1_error))\n",
    "                \n",
    "                if(backprop_type == \"momentum\"):\n",
    "                    if(count == 0):\n",
    "                        layer1_adjustment = (inputs.T.dot(layer1_grad)) * learning_rate\n",
    "                        layer2_adjustment = out_l1.T.dot(layer2_grad) * learning_rate\n",
    "                    else:\n",
    "                        ## Cálculo da regra delta com constante do momento\n",
    "                        layer1_adjustment = (alpha * temp1) + ((inputs.T.dot(layer1_grad)) * learning_rate)\n",
    "                        layer2_adjustment = (alpha * temp2) +(out_l1.T.dot(layer2_grad) * learning_rate)\n",
    "                else:\n",
    "                    ## Cálculo normal da regra delta\n",
    "                    layer1_adjustment = (inputs.T.dot(layer1_grad)) * learning_rate\n",
    "                    layer2_adjustment = out_l1.T.dot(layer2_grad) * learning_rate\n",
    "\n",
    "                self.layer1.weights += layer1_adjustment\n",
    "                temp1 = self.layer1.weights\n",
    "                self.layer2.weights += layer2_adjustment\n",
    "                temp2 = self.layer2.weights\n",
    "            else:\n",
    "                #treinamento estocástico\n",
    "                for count2 in range(samples):\n",
    "                    out_l1, out_l2 = self.classify(inputs[count2, :])\n",
    "                    #print(\"saída camada 1: \\n\" + str(out_l1) + \"\\nsaída camada 2: \\n\" + str(out_l2))\n",
    "\n",
    "                    ### Cálculo dos erros na camada 2\n",
    "                    layer2_error = expected_outs[count2, :] - out_l2\n",
    "                    layer2_grad = layer2_error * self.activation_func(\"sigmoid_deriv\",out_l2)                 # gradiente local do neurônio da camada de saída\n",
    "\n",
    "                    ## Com base no resultado da camada 2, calcular o erro na camada 1\n",
    "                    layer1_error = layer2_grad.dot(self.layer2.weights.T)\n",
    "                    layer1_grad = layer1_error * self.activation_func(\"sigmoid_deriv\",out_l1)                 # gradiente da camada 1\n",
    "\n",
    "                    ## Regra delta\n",
    "                    ar = array([inputs[count2, :]])\n",
    "                    l1_grad = array([layer1_grad])\n",
    "                    o_l1 = array([out_l1])\n",
    "                    l2_grad = array([out_l2])\n",
    "                    \n",
    "                    layer1_adjustment = (ar.T.dot(l1_grad)) * learning_rate\n",
    "                    layer2_adjustment = o_l1.T.dot(l2_grad) * learning_rate\n",
    "\n",
    "                    self.layer1.weights += layer1_adjustment\n",
    "                    temp1 = self.layer1.weights\n",
    "                    self.layer2.weights += layer2_adjustment\n",
    "                    temp2 = self.layer2.weights\n",
    "\n",
    "    def classify(self, inputs):\n",
    "        \"\"\"\n",
    "        Classifica uma entrada pela rede neural\n",
    "        Parâmetros:\n",
    "            - inputs: valor de um conjunto de treinamento/classificação\n",
    "        \"\"\"\n",
    "        output_from_layer1 = self.activation_func(\"sigmoid\", (dot(inputs, self.layer1.weights)))\n",
    "        output_from_layer2 = self.activation_func(\"sigmoid\", (dot(output_from_layer1, self.layer2.weights)))\n",
    "        return output_from_layer1, output_from_layer2\n",
    "\n",
    "    def print_weights(self):\n",
    "        print(\"Pesos da camada 1: \")\n",
    "        print (self.layer1.weights)\n",
    "        print(\"Pesos da camada 2: \")\n",
    "        print (self.layer2.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informações adicionais\n",
    "\n",
    "Foi mantida a implementação de um perceptron com apenas duas camadas. Para a questão 3, mantém-se as duas camadas de neurônios, sendo a primeira com 5 neurônios, recebendo as entradas do conjunto de treinamento, e a segunda contendo apenas 1 neurônio, recebendo como entrada as saídas dos neurônios da camada anterior.\n",
    "\n",
    "O conjunto de treinamento/classificação da questão 3a contém 200 entradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos antes de iniciar o treinamento: \n",
      "Pesos da camada 1: \n",
      "[[-0.16595599  0.44064899 -0.99977125 -0.39533485 -0.70648822]\n",
      " [-0.81532281 -0.62747958 -0.30887855 -0.20646505  0.07763347]]\n",
      "Pesos da camada 2: \n",
      "[[-0.16161097]\n",
      " [ 0.370439  ]\n",
      " [-0.5910955 ]\n",
      " [ 0.75623487]\n",
      " [-0.94522481]]\n",
      "Pesos de saída (após última iteração do treinamento): \n",
      "Pesos da camada 1: \n",
      "[[-1.73999133e+12  6.52907755e+11 -4.13268359e+12 -2.81691420e+12\n",
      "  -3.13344852e+12]\n",
      " [-2.62198223e+12 -3.65477891e+12 -3.77386437e+12  2.08403317e+11\n",
      "  -2.78570855e+12]]\n",
      "Pesos da camada 2: \n",
      "[[-9.00904556e+11]\n",
      " [ 2.13321216e+12]\n",
      " [-4.11406961e+12]\n",
      " [ 2.24851561e+12]\n",
      " [-2.63301294e+12]]\n",
      "Erros obtidos com relação aos conjuntos treinados: \n",
      "erros: 0/200\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    class_errados = 0\n",
    "    x_3a = []\n",
    "    y_3a = []\n",
    "    for line in open('./input_q3a_test.txt', 'r').readlines():\n",
    "        x_3a.append([float(num) for num in line.split(',')])\n",
    "\n",
    "    for line in open('./output_q3a_test.txt', 'r').readlines():\n",
    "        y_3a.append([int(line)])\n",
    "\n",
    "    x_3a = array(x_3a)\n",
    "    y_3a = array(y_3a)\n",
    "    smp, feat = shape(x_3a)\n",
    "    \n",
    "    LEARNING_RATE = 0.3\n",
    "\n",
    "    random.seed(1)\n",
    "\n",
    "    # Rede neural de duas camadas (setando valores (numero de neurônios e seu numero de entradas))\n",
    "    layer1 = NeuronLayer(5, 2)\n",
    "    layer2 = NeuronLayer(1, 5)\n",
    "\n",
    "    neural_network = NeuralNetwork(layer1, layer2)\n",
    "\n",
    "    # Atribuição randomica de pesos a rede neural\n",
    "    print (\"Pesos antes de iniciar o treinamento: \")\n",
    "    neural_network.print_weights()\n",
    "\n",
    "    # Conjunto de treinamento (2 exemplos com 2 valores de entrada e 1 valor de saída).\n",
    "    training_set_inputs = array([[0, 1], [0, 0], [1, 0], [1, 1]])\n",
    "    training_set_outputs = array([[1, 0, 1, 0]]).T\n",
    "\n",
    "    # treinamento da rede neural\n",
    "    neural_network.train_network(x_3a, y_3a, 300, LEARNING_RATE, \"momentum\")\n",
    "\n",
    "    print (\"Pesos de saída (após última iteração do treinamento): \")\n",
    "    neural_network.print_weights()\n",
    "\n",
    "    print(\"Erros obtidos com relação aos conjuntos treinados: \")\n",
    "    for cl_count in range(smp):\n",
    "        #print(str(x_t[cl_count,:]) + ':' + str(classify(x_t[cl_count,:])))\n",
    "        h, out = neural_network.classify(x_3a[cl_count,:])\n",
    "        if((asscalar(out) - floor(asscalar(out))) > 0.5):\n",
    "            out = ceil(asscalar(out))\n",
    "        else:\n",
    "            out = floor(asscalar(out))\n",
    "        \n",
    "        if(out != y_3a[cl_count,:]):\n",
    "            print(str(cl_count) + \"/\" + str(out) + \"\\t|\\t\" + str(y_3a[cl_count,:]))\n",
    "            class_errados = class_errados + 1\n",
    "\n",
    "    print(\"erros: \" + str(class_errados) + \"/\" + str(smp))\n",
    "\n",
    "    #print (\"Teste com entradas não treinadas: \")\n",
    "    #h, output = neural_network.classify(array([1, 1]))\n",
    "    #print(\"[1, 1] ==>\" + str(output))\n",
    "    #h, out2 = neural_network.classify(array([1, 0]))\n",
    "    #print (\"[1, 0] ==> \" + str(out2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes de saídas\n",
    "\n",
    "## Questão 3a\n",
    "\n",
    "## Regra delta com termo do momento (alpha = 0.1)\n",
    "\n",
    "#### Parâmetros:\n",
    "    - Neurônios (camada 1): 2\n",
    "    - Neurônios (camada 2): 1\n",
    "    - Taxa de aprendizado: 0.03 (teste 1), 0.3 (teste 2)\n",
    "    - Épocas: 7000 (teste 1), 300 (teste 2)\n",
    "\n",
    "##### Pesos antes de iniciar o treinamento:\n",
    "\n",
    "Pesos da camada 1:\n",
    "\n",
    "    [[-0.16595599  0.44064899]\n",
    "     [-0.99977125 -0.39533485]]\n",
    " \n",
    "Pesos da camada 2: \n",
    "\n",
    "    [[-0.70648822]\n",
    "     [-0.81532281]]\n",
    " \n",
    "##### Pesos de saída (após última iteração do treinamento): \n",
    "\n",
    "Pesos da camada 1: \n",
    "\n",
    "    [[-2.27292820e+289  1.61165308e+289]\n",
    "     [-5.42359830e+289 -2.32909492e+289]]\n",
    "   \n",
    "Pesos da camada 2: \n",
    "\n",
    "    [[-1.77661396e+289]\n",
    "     [ 4.62099080e+288]]\n",
    " \n",
    "Erros obtidos com os conjuntos treinados/classificados: \n",
    "\n",
    "    1/0 [1]\n",
    "    5/0 [1]\n",
    "    10/0 [1]\n",
    "    12/0 [1]\n",
    "    16/0 [1]\n",
    "    33/0 [1]\n",
    "    40/0 [1]\n",
    "    43/0 [1]\n",
    "    45/0 [1]\n",
    "    48/0 [1]\n",
    "    52/0 [1]\n",
    "    55/0 [1]\n",
    "    56/0 [1]\n",
    "    57/0 [1]\n",
    "    60/0 [1]\n",
    "    70/0 [1]\n",
    "    72/0 [1]\n",
    "    74/0 [1]\n",
    "    76/0 [1]\n",
    "    77/0 [1]\n",
    "    80/0 [1]\n",
    "    81/0 [1]\n",
    "    84/0 [1]\n",
    "    96/0 [1]\n",
    "    104/0 [1]\n",
    "    105/0 [1]\n",
    "    108/0 [1]\n",
    "    115/0 [1]\n",
    "    120/0 [1]\n",
    "    134/0 [1]\n",
    "    137/0 [1]\n",
    "    138/0 [1]\n",
    "    139/0 [1]\n",
    "    145/0 [1]\n",
    "    148/0 [1]\n",
    "    157/0 [1]\n",
    "    160/0 [1]\n",
    "    164/0 [1]\n",
    "    170/0 [1]\n",
    "    172/0 [1]\n",
    "    181/0 [1]\n",
    "    187/0 [1]\n",
    "    190/0 [1]\n",
    "    196/0 [1]\n",
    "    197/0 [1]\n",
    "\n",
    "#### erros: 45/200\n",
    "\n",
    "### 3º Teste\n",
    "\n",
    "#### Parâmetros:\n",
    "    - Neurônios (camada 1): 5\n",
    "    - Neurônios (camada 2): 1\n",
    "    - Taxa de aprendizado: 0.3\n",
    "    - Épocas: 300\n",
    "\n",
    "##### Pesos antes de iniciar o treinamento:\n",
    "\n",
    "Pesos da camada 1:\n",
    "\n",
    "    [[-0.16595599  0.44064899 -0.99977125 -0.39533485 -0.70648822]\n",
    "     [-0.81532281 -0.62747958 -0.30887855 -0.20646505  0.07763347]]\n",
    " \n",
    "Pesos da camada 2: \n",
    "\n",
    "    [[-0.16161097]\n",
    "     [ 0.370439  ]\n",
    "     [-0.5910955 ]\n",
    "     [ 0.75623487]\n",
    "     [-0.94522481]]\n",
    "\n",
    "##### Pesos de saída (após última iteração do treinamento): \n",
    "\n",
    "Pesos da camada 1: \n",
    "\n",
    "    [[-1.73999133e+12  6.52907755e+11 -4.13268359e+12 -2.81691420e+12\n",
    "      -3.13344852e+12]\n",
    "     [-2.62198223e+12 -3.65477891e+12 -3.77386437e+12  2.08403317e+11\n",
    "      -2.78570855e+12]]\n",
    "   \n",
    "Pesos da camada 2: \n",
    "\n",
    "    [[-9.00904556e+11]\n",
    "     [ 2.13321216e+12]\n",
    "     [-4.11406961e+12]\n",
    "     [ 2.24851561e+12]\n",
    "     [-2.63301294e+12]]\n",
    " \n",
    "Erros obtidos com os conjuntos treinados/classificados:\n",
    "#### erros: 0/200\n",
    "\n",
    "## ======================================================================   \n",
    "    \n",
    "## Backpropagation por lotes\n",
    "\n",
    "#### Parâmetros:\n",
    "    - Neurônios (camada 1): 2\n",
    "    - Neurônios (camada 2): 1\n",
    "    - Taxa de aprendizado: 0.03\n",
    "    - Épocas: 7000 (teste 1), 300 (teste 2)\n",
    "\n",
    "##### Pesos antes de iniciar o treinamento:\n",
    "\n",
    "Pesos da camada 1:\n",
    "\n",
    "    [[-0.16595599  0.44064899]\n",
    "     [-0.99977125 -0.39533485]]\n",
    " \n",
    "Pesos da camada 2: \n",
    "\n",
    "    [[-0.70648822]\n",
    "     [-0.81532281]]\n",
    " \n",
    "##### Pesos de saída (após última iteração do treinamento): \n",
    "\n",
    "Pesos da camada 1: \n",
    "\n",
    "    [[-5.34716684  1.61636268]\n",
    "     [-9.47389516 -9.78770329]]\n",
    "   \n",
    "Pesos da camada 2: \n",
    "\n",
    "    [[-13.00886677]\n",
    "     [  4.99981404]]\n",
    " \n",
    "Erros obtidos com os conjuntos treinados/classificados:\n",
    "\n",
    "    1/0 [1]\n",
    "    5/0 [1]\n",
    "    9/1 [0]\n",
    "    10/0 [1]\n",
    "    11/1 [0]\n",
    "    12/0 [1]\n",
    "    16/0 [1]\n",
    "    25/1 [0]\n",
    "    28/1 [0]\n",
    "    33/0 [1]\n",
    "    38/1 [0]\n",
    "    40/0 [1]\n",
    "    43/0 [1]\n",
    "    44/1 [0]\n",
    "    45/0 [1]\n",
    "    46/1 [0]\n",
    "    48/0 [1]\n",
    "    49/1 [0]\n",
    "    51/1 [0]\n",
    "    52/0 [1]\n",
    "    55/0 [1]\n",
    "    56/0 [1]\n",
    "    57/0 [1]\n",
    "    60/0 [1]\n",
    "    63/1 [0]\n",
    "    65/1 [0]\n",
    "    70/0 [1]\n",
    "    72/0 [1]\n",
    "    74/0 [1]\n",
    "    76/0 [1]\n",
    "    77/0 [1]\n",
    "    79/1 [0]\n",
    "    80/0 [1]\n",
    "    81/0 [1]\n",
    "    84/0 [1]\n",
    "    87/1 [0]\n",
    "    88/1 [0]\n",
    "    91/1 [0]\n",
    "    92/1 [0]\n",
    "    96/0 [1]\n",
    "    98/1 [0]\n",
    "    99/1 [0]\n",
    "    101/1 [0]\n",
    "    102/1 [0]\n",
    "    104/0 [1]\n",
    "    105/0 [1]\n",
    "    107/1 [0]\n",
    "    108/0 [1]\n",
    "    110/1 [0]\n",
    "    112/1 [0]\n",
    "    115/0 [1]\n",
    "    117/1 [0]\n",
    "    120/0 [1]\n",
    "    122/1 [0]\n",
    "    124/1 [0]\n",
    "    125/1 [0]\n",
    "    130/1 [0]\n",
    "    132/1 [0]\n",
    "    134/0 [1]\n",
    "    137/0 [1]\n",
    "    138/0 [1]\n",
    "    139/0 [1]\n",
    "    140/1 [0]\n",
    "    144/1 [0]\n",
    "    145/0 [1]\n",
    "    146/1 [0]\n",
    "    147/1 [0]\n",
    "    148/0 [1]\n",
    "    149/1 [0]\n",
    "    152/1 [0]\n",
    "    153/1 [0]\n",
    "    157/0 [1]\n",
    "    160/0 [1]\n",
    "    162/1 [0]\n",
    "    164/0 [1]\n",
    "    166/1 [0]\n",
    "    167/1 [0]\n",
    "    168/1 [0]\n",
    "    170/0 [1]\n",
    "    172/0 [1]\n",
    "    173/1 [0]\n",
    "    177/1 [0]\n",
    "    178/1 [0]\n",
    "    179/1 [0]\n",
    "    181/0 [1]\n",
    "    184/1 [0]\n",
    "    186/1 [0]\n",
    "    187/0 [1]\n",
    "    190/0 [1]\n",
    "    191/1 [0]\n",
    "    193/1 [0]\n",
    "    195/1 [0]\n",
    "    196/0 [1]\n",
    "    197/0 [1]\n",
    "    \n",
    "#### erros: 94/200\n",
    "\n",
    "### 3º Teste\n",
    "\n",
    "#### Parâmetros:\n",
    "    - Neurônios (camada 1): 5\n",
    "    - Neurônios (camada 2): 1\n",
    "    - Taxa de aprendizado: 0.03\n",
    "    - Épocas: 300\n",
    "\n",
    "##### Pesos antes de iniciar o treinamento:\n",
    "\n",
    "Pesos da camada 1:\n",
    "\n",
    "    [[-0.16595599  0.44064899 -0.99977125 -0.39533485 -0.70648822]\n",
    "     [-0.81532281 -0.62747958 -0.30887855 -0.20646505  0.07763347]]\n",
    " \n",
    "Pesos da camada 2: \n",
    "\n",
    "    [[-0.16161097]\n",
    "     [ 0.370439  ]\n",
    "     [-0.5910955 ]\n",
    "     [ 0.75623487]\n",
    "     [-0.94522481]]\n",
    "\n",
    "##### Pesos de saída (após última iteração do treinamento): \n",
    "\n",
    "Pesos da camada 1: \n",
    "\n",
    "    [[-0.60954743  3.67807678 -5.7222896  -6.73062165  2.81402682]\n",
    "     [-1.14172501 -7.58120461 -5.6219779   3.08148804 -1.13208129]]\n",
    "   \n",
    "Pesos da camada 2: \n",
    "\n",
    "    [[ -1.05126187]\n",
    "     [  9.52382592]\n",
    "     [-17.20530964]\n",
    "     [  5.93749338]\n",
    "     [ -5.10104222]]\n",
    " \n",
    "Erros obtidos com os conjuntos treinados/classificados:\n",
    "#### erros: 0/200\n",
    "\n",
    "## ======================================================================   \n",
    "    \n",
    "### Backpropagation estocástico\n",
    "\n",
    "#### Parâmetros:\n",
    "    - Neurônios (camada 1): 5\n",
    "    - Neurônios (camada 2): 1\n",
    "    - Taxa de aprendizado: 0.3\n",
    "    - Épocas: 300\n",
    "\n",
    "##### Pesos antes de iniciar o treinamento:\n",
    "\n",
    "Pesos da camada 1:\n",
    "\n",
    "    [[-0.16595599  0.44064899 -0.99977125 -0.39533485 -0.70648822]\n",
    "     [-0.81532281 -0.62747958 -0.30887855 -0.20646505  0.07763347]]\n",
    " \n",
    "Pesos da camada 2: \n",
    "\n",
    "    [[-0.16161097]\n",
    "     [ 0.370439  ]\n",
    "     [-0.5910955 ]\n",
    "     [ 0.75623487]\n",
    "     [-0.94522481]]\n",
    "\n",
    "##### Pesos de saída (após última iteração do treinamento): \n",
    "\n",
    "Pesos da camada 1: \n",
    "\n",
    "    [[-0.17701543  0.41801125 -1.00585525 -0.41761916 -0.7124805 ]\n",
    "     [-0.82551895 -0.64341212 -0.31913473 -0.2170345   0.06361007]]\n",
    "   \n",
    "Pesos da camada 2: \n",
    "\n",
    "    [[6968.20131037]\n",
    "     [8632.26813296]\n",
    "     [6250.03425577]\n",
    "     [7594.68077771]\n",
    "     [7525.28891091]]\n",
    "\n",
    "Erros obtidos com os conjuntos treinados/classificados:\n",
    "\n",
    "    0/1\t|\t[0]\n",
    "    2/1\t|\t[0]\n",
    "    4/1\t|\t[0]\n",
    "    6/1\t|\t[0]\n",
    "    7/1\t|\t[0]\n",
    "    9/1\t|\t[0]\n",
    "    11/1\t|\t[0]\n",
    "    13/1\t|\t[0]\n",
    "    18/1\t|\t[0]\n",
    "    19/1\t|\t[0]\n",
    "    20/1\t|\t[0]\n",
    "    22/1\t|\t[0]\n",
    "    23/1\t|\t[0]\n",
    "    25/1\t|\t[0]\n",
    "    28/1\t|\t[0]\n",
    "    30/1\t|\t[0]\n",
    "    34/1\t|\t[0]\n",
    "    36/1\t|\t[0]\n",
    "    37/1\t|\t[0]\n",
    "    38/1\t|\t[0]\n",
    "    44/1\t|\t[0]\n",
    "    46/1\t|\t[0]\n",
    "    49/1\t|\t[0]\n",
    "    50/1\t|\t[0]\n",
    "    51/1\t|\t[0]\n",
    "    54/1\t|\t[0]\n",
    "    58/1\t|\t[0]\n",
    "    59/1\t|\t[0]\n",
    "    62/1\t|\t[0]\n",
    "    63/1\t|\t[0]\n",
    "    65/1\t|\t[0]\n",
    "    67/1\t|\t[0]\n",
    "    68/1\t|\t[0]\n",
    "    71/1\t|\t[0]\n",
    "    73/1\t|\t[0]\n",
    "    78/1\t|\t[0]\n",
    "    79/1\t|\t[0]\n",
    "    82/1\t|\t[0]\n",
    "    83/1\t|\t[0]\n",
    "    87/1\t|\t[0]\n",
    "    88/1\t|\t[0]\n",
    "    90/1\t|\t[0]\n",
    "    91/1\t|\t[0]\n",
    "    92/1\t|\t[0]\n",
    "    94/1\t|\t[0]\n",
    "    97/1\t|\t[0]\n",
    "    98/1\t|\t[0]\n",
    "    99/1\t|\t[0]\n",
    "    100/1\t|\t[0]\n",
    "    101/1\t|\t[0]\n",
    "    102/1\t|\t[0]\n",
    "    106/1\t|\t[0]\n",
    "    107/1\t|\t[0]\n",
    "    110/1\t|\t[0]\n",
    "    111/1\t|\t[0]\n",
    "    112/1\t|\t[0]\n",
    "    116/1\t|\t[0]\n",
    "    117/1\t|\t[0]\n",
    "    121/1\t|\t[0]\n",
    "    122/1\t|\t[0]\n",
    "    124/1\t|\t[0]\n",
    "    125/1\t|\t[0]\n",
    "    126/1\t|\t[0]\n",
    "    129/1\t|\t[0]\n",
    "    130/1\t|\t[0]\n",
    "    132/1\t|\t[0]\n",
    "    133/1\t|\t[0]\n",
    "    135/1\t|\t[0]\n",
    "    136/1\t|\t[0]\n",
    "    140/1\t|\t[0]\n",
    "    141/1\t|\t[0]\n",
    "    144/1\t|\t[0]\n",
    "    146/1\t|\t[0]\n",
    "    147/1\t|\t[0]\n",
    "    149/1\t|\t[0]\n",
    "    150/1\t|\t[0]\n",
    "    152/1\t|\t[0]\n",
    "    153/1\t|\t[0]\n",
    "    156/1\t|\t[0]\n",
    "    158/1\t|\t[0]\n",
    "    161/1\t|\t[0]\n",
    "    162/1\t|\t[0]\n",
    "    165/1\t|\t[0]\n",
    "    166/1\t|\t[0]\n",
    "    167/1\t|\t[0]\n",
    "    168/1\t|\t[0]\n",
    "    173/1\t|\t[0]\n",
    "    176/1\t|\t[0]\n",
    "    177/1\t|\t[0]\n",
    "    178/1\t|\t[0]\n",
    "    179/1\t|\t[0]\n",
    "    180/1\t|\t[0]\n",
    "    184/1\t|\t[0]\n",
    "    185/1\t|\t[0]\n",
    "    186/1\t|\t[0]\n",
    "    188/1\t|\t[0]\n",
    "    191/1\t|\t[0]\n",
    "    193/1\t|\t[0]\n",
    "    195/1\t|\t[0]\n",
    "    198/1\t|\t[0]\n",
    "\n",
    "#### erros: 100/200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
