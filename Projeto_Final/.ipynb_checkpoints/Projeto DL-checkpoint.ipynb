{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto - Deep Learning\n",
    "\n",
    "## Classificação de Espectogramas\n",
    "\n",
    "Equipe: Francisco Mateus, Matheus Praxedes e Thiago Viana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importações utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten,Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura, visualização e pré-processamento do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = io.imread(\"dataset/01VGE.png\", as_gray=True)\n",
    "#io.imshow(img)  \n",
    "\n",
    "path = './dataset/'\n",
    "img_number = [int(image_name[0:len(image_name)-7]) for image_name in os.listdir(path)]\n",
    "img_number.sort()\n",
    "\n",
    "#image_names = [cv2.imread(path+img_name, cv2.IMREAD_GRAYSCALE) for img_name in os.listdir(path)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação da Rede Neural\n",
    "\n",
    "O que precisa ser feito:\n",
    "    - Dividir as instâncias (treinamento (80%), validação e teste (20%))\n",
    "    - Desenvolvimento da arquitetura da rede\n",
    "        - Rede Convolucional\n",
    "            - 5 camadas convolucionais (1a com stride 2x1, o restante com stride 1x1) alternadas com camadas de pooling (stride 2x2) (função ReLU) [ok]\n",
    "                - camada de entrada tem dropout 0.2 [ok]\n",
    "            - 1 camada densa (1024 unidades, ReLU, dropout 0.4) + camada de saída (1000 unidades, softmax, dropout 0.4) [ok]\n",
    "        - Função custo: categorical_crossentropy [ok]\n",
    "        - Batch size: 16 [ok]\n",
    "        - Otimizador: Adam ou SGD com momento de Nesterov (momento = 0.9, LR = 0.1)\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "espec_table = pd.read_csv(\"./spectrogram_table.csv\")\n",
    "espec_table.drop(columns = ['Pres, Desvio EAV-G (VGe)', 'GRUPO DIAGNÓSTICO'], inplace = True)\n",
    "espec_table.dropna(inplace = True)\n",
    "espec_table = espec_table[espec_table[\"NÚMERO PACT\"].isin(img_number)]\n",
    "\n",
    "## Train, Test and Validation (rótulos)\n",
    "class1 = espec_table[espec_table[\"CLASSIFICAÇÃO ESPECTROGRAMA\"] == 1.0].reset_index(drop = True)\n",
    "test1 = class1.sample(frac = 0.2, replace = False)\n",
    "train1 = class1[~class1.index.isin(test1.index)]\n",
    "val1 = test1.sample(frac=0.5, replace=False)\n",
    "test1 = test1[~test1.index.isin(val1.index)]\n",
    "\n",
    "class2 = espec_table[espec_table[\"CLASSIFICAÇÃO ESPECTROGRAMA\"] == 2.0].reset_index(drop = True)\n",
    "test2 = class2.sample(frac = 0.2, replace = False)\n",
    "train2 = class2[~class2.index.isin(test2.index)]\n",
    "val2 = test2.sample(frac=0.5, replace=False)\n",
    "test2 = test2[~test2.index.isin(val2.index)]\n",
    "\n",
    "class3 = espec_table[espec_table[\"CLASSIFICAÇÃO ESPECTROGRAMA\"] == 3.0].reset_index(drop = True)\n",
    "test3 = class3.sample(frac = 0.2, replace = False)\n",
    "train3 = class3[~class3.index.isin(test3.index)]\n",
    "val3 = test3.sample(frac=0.5, replace=False)\n",
    "test3 = test3[~test3.index.isin(val3.index)]\n",
    "\n",
    "class4 = espec_table[espec_table[\"CLASSIFICAÇÃO ESPECTROGRAMA\"] == 4.0].reset_index(drop = True)\n",
    "test4 = class4.sample(frac = 0.2, replace = False)\n",
    "train4 = class4[~class4.index.isin(test4.index)]\n",
    "val4 = test4.sample(frac=0.5, replace=False)\n",
    "test4 = test4[~test4.index.isin(val4.index)]\n",
    "\n",
    "test = pd.concat([test1,test2,test3,test4]).sample(frac = 1.0, replace = False).reset_index(drop = True)\n",
    "train = pd.concat([train1,train2,train3,train4]).sample(frac = 1.0, replace = False).reset_index(drop = True)\n",
    "validation = pd.concat([val1,val2,val3,val4]).sample(frac = 1.0, replace = False).reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train_names = (train['NÚMERO PACT'].astype(str) + 'VGE.png').tolist()\n",
    "img_val_names = (validation['NÚMERO PACT'].astype(str) + 'VGE.png').tolist()\n",
    "img_test_names = (test['NÚMERO PACT'].astype(str) + 'VGE.png').tolist()\n",
    "\n",
    "img_train = []\n",
    "img_val = []\n",
    "img_test = []\n",
    "height, width = 824, 419\n",
    "\n",
    "for img_name in img_train_names:\n",
    "    img = cv2.imread(path+img_name, cv2.IMREAD_GRAYSCALE)\n",
    "    info = np.iinfo(img.dtype) \n",
    "    img = img.astype(np.float64) / info.max\n",
    "    img = cv2.resize(img, (width, height), cv2.INTER_AREA)\n",
    "    img = np.expand_dims(img, axis = 2)\n",
    "    img_train.append(img)\n",
    "    \n",
    "for img_name in img_val_names:\n",
    "    img = cv2.imread(path+img_name, cv2.IMREAD_GRAYSCALE)\n",
    "    info = np.iinfo(img.dtype) \n",
    "    img = img.astype(np.float64) / info.max\n",
    "    img = cv2.resize(img, (width, height), cv2.INTER_AREA)\n",
    "    img = np.expand_dims(img, axis = 2)\n",
    "    img_val.append(img)\n",
    "    \n",
    "for img_name in img_test_names:\n",
    "    img = cv2.imread(path+img_name, cv2.IMREAD_GRAYSCALE)\n",
    "    info = np.iinfo(img.dtype) \n",
    "    img = img.astype(np.float64) / info.max\n",
    "    img = cv2.resize(img, (width, height), cv2.INTER_AREA)\n",
    "    img = np.expand_dims(img, axis = 2)\n",
    "    img_test.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(img_train)\n",
    "x_val = np.array(img_val)\n",
    "x_test = np.array(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = train['CLASSIFICAÇÃO ESPECTROGRAMA'].tolist()\n",
    "val_list = validation['CLASSIFICAÇÃO ESPECTROGRAMA'].tolist()\n",
    "test_list = test['CLASSIFICAÇÃO ESPECTROGRAMA'].tolist()\n",
    "\n",
    "y_train = []\n",
    "y_val = []\n",
    "y_test = []\n",
    "\n",
    "for element in train_list:\n",
    "    go = np.array(np.zeros([4], dtype = np.uint8))\n",
    "    go[int(element)-1] = 1\n",
    "    y_train.append(go)\n",
    "    \n",
    "for element in val_list:\n",
    "    go = np.array(np.zeros([4], dtype = np.uint8))\n",
    "    go[int(element)-1] = 1\n",
    "    y_val.append(go)\n",
    "\n",
    "for element in test_list:\n",
    "    go = np.array(np.zeros([4], dtype = np.uint8))\n",
    "    go[int(element)-1] = 1\n",
    "    y_test.append(go)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Arquitetura da rede convolucional\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(5, 5), strides=(2,1), activation ='relu', input_shape = (824, 419, 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    " \n",
    "model.add(Conv2D(64, kernel_size=(5, 5), strides=(1,1), activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    " \n",
    "model.add(Conv2D(128, kernel_size=(5, 5), strides=(1,1), activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    " \n",
    "model.add(Conv2D(256, kernel_size=(5, 5), strides=(1,1), activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    " \n",
    "model.add(Conv2D(256, kernel_size=(3, 3), strides=(1,1), activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "model.add(Flatten())\n",
    " \n",
    "model.add(Dense(1024, activation ='relu'))\n",
    "model.add(Dropout(0.4))\n",
    " \n",
    "model.add(Dense(1000, activation ='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(4, activation ='softmax'))\n",
    " \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Treinamento e avaliação da CNN\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=1, verbose=1, batch_size=16, validation_data=(x_val, y_val))\n",
    "\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(\"Training %s: %.2f%%\" % (arch1_model.metrics_names[1], scores[1]*100))\n",
    "print(\"Training loss: %.4f\" % (scores[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gráfico de acurácia\n",
    "plt.figure(figsize=(16,11))\n",
    "plt.plot(history.history['acc'], color='red')\n",
    "plt.plot(history.history['val_acc'], color='blue')\n",
    "plt.title('curva de treinamento')\n",
    "plt.ylabel('acurácia')\n",
    "plt.legend(['Treinamento', 'Validação'], loc='upper left')\n",
    "plt.xlabel('época')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gráfico de erro\n",
    "plt.figure(figsize=(16,11))\n",
    "plt.plot(history.history['loss'], color='red')\n",
    "plt.plot(history.history['val_loss'], color='blue')\n",
    "plt.title('curva de treinamento')\n",
    "plt.ylabel('erro')\n",
    "plt.legend(['Treinamento', 'Validação'], loc='upper left')\n",
    "plt.xlabel('época')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrizes de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score = accuracy_score(y_train, np.round(model.predict(x_train)))\n",
    "matrix = confusion_matrix(y_train, np.round(model.predict(x_train)))\n",
    "print('Acurácia (treinamento): %.2f' % acc_score)\n",
    "print('Matriz de Confusão (treinamento): \\n', matrix)\n",
    "print('\\n\\n')\n",
    "\n",
    "acc_score2 = accuracy_score(y_test, np.round(model.predict(x_test)))\n",
    "matrix2 = confusion_matrix(y_test, np.round(model.predict(x_test)))\n",
    "print('Acurácia (teste): %.2f' % acc_score2)\n",
    "print('Matriz de Confusão (teste): \\n', matrix2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
