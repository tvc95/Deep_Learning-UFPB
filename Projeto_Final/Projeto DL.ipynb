{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto - Deep Learning\n",
    "\n",
    "## Classificação de Espectogramas\n",
    "\n",
    "Equipe: Francisco Mateus, Matheus Praxedes e Thiago Viana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importações utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura, visualização e pré-processamento do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = io.imread(\"dataset/01VGE.png\", as_gray=True)\n",
    "#io.imshow(img)  \n",
    "\n",
    "path = \"./dataset/\"\n",
    "paths = []\n",
    "\n",
    "for image_path in os.listdir(path):\n",
    "    paths.append(path+image_path)\n",
    "  \n",
    "\n",
    "all_images = io.imread_collection(paths ,True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação da Rede Neural\n",
    "\n",
    "O que precisa ser feito:\n",
    "    - Dividir as instâncias (treinamento (80%), validação e teste (20%))\n",
    "    - Desenvolvimento da arquitetura da rede\n",
    "        - Rede Convolucional\n",
    "            - 5 camadas convolucionais (1a com stride 2x1, o restante com stride 1x1) alternadas com camadas de pooling (stride 2x2) (função ReLU) [ok]\n",
    "                - camada de entrada tem dropout 0.2 [ok]\n",
    "            - 1 camada densa (1024 unidades, ReLU, dropout 0.4) + camada de saída (1000 unidades, softmax, dropout 0.4) [ok]\n",
    "        - Função custo: categorical_crossentropy [ok]\n",
    "        - Batch size: 16 [ok]\n",
    "        - Otimizador: Adam ou SGD com momento de Nesterov (momento = 0.9, LR = 0.1)\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "904"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "espec_table = pd.read_csv(\"./spectrogram_table.csv\")\n",
    "\n",
    "espec_table.drop(columns = ['Pres, Desvio EAV-G (VGe)', 'GRUPO DIAGNÓSTICO'], inplace = True)\n",
    "\n",
    "espec_table.dropna(inplace = True)\n",
    "\n",
    "img_number = [int(image_name[0:len(image_name)-7]) for image_name in os.listdir(path)]\n",
    "img_number.sort()\n",
    "\n",
    "espec_table = espec_table[espec_table[\"NÚMERO PACT\"].isin(img_number)]\n",
    "\n",
    "## Train, Test and Validation (rótulos)\n",
    "class1 = espec_table[espec_table[\"CLASSIFICAÇÃO ESPECTROGRAMA\"] == 1.0].reset_index(drop = True)\n",
    "y_test1 = class1.sample(frac = 0.2, replace = False)\n",
    "y_train1 = class1[~class1.index.isin(y_test1.index)]\n",
    "y_val1 = y_test1.sample(frac=0.5, replace=False)\n",
    "y_test1 = y_test1[~y_test1.index.isin(y_val1.index)]\n",
    "\n",
    "class2 = espec_table[espec_table[\"CLASSIFICAÇÃO ESPECTROGRAMA\"] == 2.0].reset_index(drop = True)\n",
    "y_test2 = class2.sample(frac = 0.2, replace = False)\n",
    "y_train2 = class2[~class2.index.isin(y_test2.index)]\n",
    "y_val2 = y_test2.sample(frac=0.5, replace=False)\n",
    "y_test2 = y_test2[~y_test2.index.isin(y_val2.index)]\n",
    "\n",
    "class3 = espec_table[espec_table[\"CLASSIFICAÇÃO ESPECTROGRAMA\"] == 3.0].reset_index(drop = True)\n",
    "y_test3 = class3.sample(frac = 0.2, replace = False)\n",
    "y_train3 = class3[~class3.index.isin(y_test3.index)]\n",
    "y_val3 = y_test3.sample(frac=0.5, replace=False)\n",
    "y_test3 = y_test3[~y_test3.index.isin(y_val3.index)]\n",
    "\n",
    "class4 = espec_table[espec_table[\"CLASSIFICAÇÃO ESPECTROGRAMA\"] == 4.0].reset_index(drop = True)\n",
    "y_test4 = class4.sample(frac = 0.2, replace = False)\n",
    "y_train4 = class4[~class4.index.isin(y_test4.index)]\n",
    "y_val4 = y_test4.sample(frac=0.5, replace=False)\n",
    "y_test4 = y_test4[~y_test4.index.isin(y_val4.index)]\n",
    "\n",
    "y_test = pd.concat([y_test1,y_test2,y_test3,y_test4]).sample(frac = 1.0, replace = False).reset_index(drop = True)\n",
    "y_train = pd.concat([y_train1,y_train2,y_train3,y_train4]).sample(frac = 1.0, replace = False).reset_index(drop = True)\n",
    "y_validation = pd.concat([y_val1,y_val2,y_val3,y_val4]).sample(frac = 1.0, replace = False).reset_index(drop = True)\n",
    "\n",
    "y_test = y_test.filter(['CLASSIFICAÇÃO ESPECTROGRAMA'], axis = 1)\n",
    "y_train = y_train.filter(['CLASSIFICAÇÃO ESPECTROGRAMA'], axis = 1)\n",
    "y_validation = y_validation.filter(['CLASSIFICAÇÃO ESPECTROGRAMA'], axis = 1)\n",
    "\n",
    "display(len(y_test))\n",
    "display(len(y_train))\n",
    "display(len(y_validation))\n",
    "display(len(x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Arquitetura da rede convolucional\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(5, 5), strides=(2,1), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(5, 5), strides=(1,1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(5, 5), strides=(1,1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(5, 5), strides=(1,1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), strides=(1,1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(1000, activation='softmax'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Treinamento e avaliação da CNN\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=1000, verbose=0, batch_size=16, validation_data=(x_test, y_test))\n",
    "\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(\"Training %s: %.2f%%\" % (arch1_model.metrics_names[1], scores[1]*100))\n",
    "print(\"Training loss: %.4f\" % (scores[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gráfico de acurácia\n",
    "plt.figure(figsize=(16,11))\n",
    "plt.plot(history.history['acc'], color='red')\n",
    "plt.plot(history.history['val_acc'], color='blue')\n",
    "plt.title('curva de treinamento')\n",
    "plt.ylabel('acurácia')\n",
    "plt.legend(['Treinamento', 'Validação'], loc='upper left')\n",
    "plt.xlabel('época')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gráfico de erro\n",
    "plt.figure(figsize=(16,11))\n",
    "plt.plot(history.history['loss'], color='red')\n",
    "plt.plot(history.history['val_loss'], color='blue')\n",
    "plt.title('curva de treinamento')\n",
    "plt.ylabel('erro')\n",
    "plt.legend(['Treinamento', 'Validação'], loc='upper left')\n",
    "plt.xlabel('época')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrizes de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score = accuracy_score(y_train, np.round(model.predict(x_train)))\n",
    "matrix = confusion_matrix(y_train, np.round(model.predict(x_train)))\n",
    "print('Acurácia (treinamento): %.2f' % acc_score)\n",
    "print('Matriz de Confusão (treinamento): \\n', matrix)\n",
    "print('\\n\\n')\n",
    "\n",
    "acc_score2 = accuracy_score(y_test, np.round(model.predict(x_test)))\n",
    "matrix2 = confusion_matrix(y_test, np.round(model.predict(x_test)))\n",
    "print('Acurácia (teste): %.2f' % acc_score2)\n",
    "print('Matriz de Confusão (teste): \\n', matrix2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
